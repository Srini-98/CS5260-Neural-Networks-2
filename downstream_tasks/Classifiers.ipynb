{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E0': tensor([[-0.1871,  0.2282, -0.1727,  ...,  0.1472,  0.2910, -0.3862],\n",
       "         [-0.3664,  0.3472, -1.1609,  ..., -0.0622,  0.0587, -0.4521],\n",
       "         [-0.0877,  0.1031, -0.2516,  ...,  0.2156,  0.2691, -0.1084],\n",
       "         ...,\n",
       "         [ 0.2111,  0.6596, -0.1330,  ..., -0.1103,  0.8673, -0.4251],\n",
       "         [-0.8579,  1.2079, -0.4490,  ..., -0.8057,  0.5456, -1.3085],\n",
       "         [-0.8488,  0.5984, -0.7300,  ..., -0.3546, -0.1988, -0.0395]],\n",
       "        requires_grad=True),\n",
       " 'E1': tensor([[ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832],\n",
       "         [ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832],\n",
       "         [ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832],\n",
       "         ...,\n",
       "         [ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832],\n",
       "         [ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832],\n",
       "         [ 0.0860,  0.0018,  0.0369,  ...,  0.0829,  0.0690, -0.0832]],\n",
       "        requires_grad=True),\n",
       " 'E2': tensor([[-0.0337, -0.0328, -0.0138,  ..., -0.0420, -0.0563, -0.0697],\n",
       "         [-0.0615,  0.2146,  0.0354,  ..., -0.1213,  0.1493, -0.1319],\n",
       "         [-1.5574,  2.5593, -0.8181,  ..., -0.5980, -0.9611, -1.1648],\n",
       "         ...,\n",
       "         [-0.0337, -0.0328, -0.0138,  ..., -0.0420, -0.0563, -0.0697],\n",
       "         [-0.5366, -1.4764,  2.1612,  ..., -2.6988,  1.0245,  1.3181],\n",
       "         [-2.4985,  3.9461, -4.2078,  ..., -0.1464,  7.0440, -1.3075]],\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file = open('googleNet_embeddings.pkl', 'rb')\n",
    "# embeddings = torch.load('../matrix_factorization/InceptionNet_embeddings.pkl')\n",
    "embeddings = torch.load(\"../matrix_factorization/sentenceBert_cnn_encoder_decoder.pkl\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "../dataset/train_book_id.pkl is a zip archive (did you mean to use torch.jit.load()?)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidHeaderError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2298\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2299\u001b[1;33m                 \u001b[0mtarinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtarfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2300\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEOFHeaderError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mfromtarfile\u001b[1;34m(cls, tarfile)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBLOCKSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mfrombuf\u001b[1;34m(cls, buf, encoding, errors)\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchksum\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcalc_chksums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidHeaderError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad checksum\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidHeaderError\u001b[0m: bad checksum",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlegacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mlegacy_load\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAX_FORMAT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m                 \u001b[0mmkdtemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unknown compression type %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mtaropen\u001b[1;34m(cls, name, mode, fileobj, **kwargs)\u001b[0m\n\u001b[0;32m   1620\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode must be 'r', 'a', 'w' or 'x'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1621\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2310\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2311\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2312\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmptyHeaderError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadError\u001b[0m: bad checksum",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-34442809df8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../dataset/train_book_id.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../dataset/test_book_id.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\91984\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;31m# .zip is used for torch.jit.save and will throw an un-pickling error here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} is a zip archive (did you mean to use torch.jit.load()?)\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m             \u001b[1;31m# if not a tarfile, reset file offset and proceed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ../dataset/train_book_id.pkl is a zip archive (did you mean to use torch.jit.load()?)"
     ]
    }
   ],
   "source": [
    "train_ids = torch.load(\"../dataset/train_book_id.pkl\")\n",
    "test_ids = torch.load(\"../dataset/test_book_id.pkl\")\n",
    "print(train_ids.size())\n",
    "print(test_ids.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>series</th>\n",
       "      <th>country_code</th>\n",
       "      <th>language_code</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>asin</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>kindle_asin</th>\n",
       "      <th>...</th>\n",
       "      <th>mystery, thriller, crime</th>\n",
       "      <th>poetry</th>\n",
       "      <th>romance</th>\n",
       "      <th>non-fiction</th>\n",
       "      <th>children</th>\n",
       "      <th>young-adult</th>\n",
       "      <th>comics, graphic</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_category</th>\n",
       "      <th>is_fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>['189911']</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '58', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>B00071IKUY</td>\n",
       "      <td>False</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fantasy, paranormal</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0842379428</td>\n",
       "      <td>566</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '6393', 'name': 'to-read'}, {'count...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.26</td>\n",
       "      <td>B000FCKCJC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0590417010</td>\n",
       "      <td>193</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '450', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.43</td>\n",
       "      <td>B017RORXNI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400041694</td>\n",
       "      <td>44</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>en-US</td>\n",
       "      <td>[{'count': '362', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3.75</td>\n",
       "      <td>B002OTKEP6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '8', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poetry</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn  text_reviews_count      series country_code language_code  \\\n",
       "0         NaN                   7  ['189911']           US           eng   \n",
       "1  0842379428                 566          []           US           eng   \n",
       "2  0590417010                 193          []           US           eng   \n",
       "3  1400041694                  44          []           US         en-US   \n",
       "4         NaN                   1          []           US           eng   \n",
       "\n",
       "                                     popular_shelves        asin  is_ebook  \\\n",
       "0  [{'count': '58', 'name': 'to-read'}, {'count':...  B00071IKUY     False   \n",
       "1  [{'count': '6393', 'name': 'to-read'}, {'count...         NaN     False   \n",
       "2  [{'count': '450', 'name': 'to-read'}, {'count'...         NaN     False   \n",
       "3  [{'count': '362', 'name': 'to-read'}, {'count'...         NaN     False   \n",
       "4  [{'count': '8', 'name': 'to-read'}, {'count': ...         NaN     False   \n",
       "\n",
       "   average_rating kindle_asin  ... mystery, thriller, crime poetry romance  \\\n",
       "0            4.03         NaN  ...                      1.0    1.0     NaN   \n",
       "1            4.26  B000FCKCJC  ...                      NaN    NaN     NaN   \n",
       "2            4.43  B017RORXNI  ...                      NaN    NaN     NaN   \n",
       "3            3.75  B002OTKEP6  ...                      NaN    NaN     NaN   \n",
       "4            3.83         NaN  ...                      NaN    3.0     NaN   \n",
       "\n",
       "  non-fiction children young-adult  comics, graphic             category  \\\n",
       "0         NaN      NaN         NaN              NaN  fantasy, paranormal   \n",
       "1       163.0      NaN         NaN              NaN          non-fiction   \n",
       "2         2.0    109.0         1.0              NaN             children   \n",
       "3        37.0      NaN         NaN              NaN          non-fiction   \n",
       "4         NaN      NaN         NaN              NaN               poetry   \n",
       "\n",
       "  binary_category  is_fiction  \n",
       "0         fiction           1  \n",
       "1     non-fiction           0  \n",
       "2     non-fiction           0  \n",
       "3     non-fiction           0  \n",
       "4     non-fiction           0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/books_with_genres.csv\")\n",
    "df['is_fiction'] = df['binary_category'].apply(lambda x: 1 if x=='fiction' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 50)\n",
      "(1000, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train = embeddings[\"E0\"][0:4000].detach().numpy()\n",
    "X_test = embeddings[\"E0\"][4000:].detach().numpy()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = df[\"is_fiction\"][0:4000]\n",
    "y_test = df[\"is_fiction\"][4000:]\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.7782529016493586\n",
      "accuarcy:  0.637\n",
      "precision:  0.637\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "score = f1_score(y_test, preds)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "print('f1_score: ', score)\n",
    "print('accuarcy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.7773677736777367\n",
      "accuarcy:  0.638\n",
      "precision:  0.6390293225480284\n",
      "recall:  0.9921507064364207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0).fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "score = f1_score(y_test, preds)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "print('f1_score: ', score)\n",
    "print('accuarcy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.7197231833910034\n",
      "accuarcy:  0.595\n",
      "precision:  0.6435643564356436\n",
      "recall:  0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "score = f1_score(y_test, preds)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "print('f1_score: ', score)\n",
    "print('accuarcy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
